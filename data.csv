"Item type","Authors","Title","Journal","Full journal","Publication year","Volume","Issue","Pages","Folders filed in","Labels filed in","Publisher","Address","Proceedings title","Conference","Conference location","Date published","ISSN","URLs","DOI","Arxiv ID","Abstract","Notes","Copyright","Archive prefix","Eprint ID","Primary class","BibTeX key","Source"
"Preprint Manuscript","Madsen A,Reddy S,Chandar S","Post-hoc Interpretability for Neural NLP: A Survey","","","2021","","","","PhD;PhD/To Read","Interpretability;INT - Causal attribution;INT - Counterfactuals;INT - Robustness;INT - Extrinsic;MET - Survey;Meta","","","","","","2021-08-10","","http://arxiv.org/abs/2108.04840","","2108.04840","Natural Language Processing (NLP) models have become increasingly more complex and widespread. With recent developments in neural networks, a growing concern is whether it is responsible to use these models. Concerns such as safety and ethics can be partially addressed by providing explanations. Furthermore, when models do fail, providing explanations is paramount for accountability purposes. To this end, interpretability serves to provide these explanations in terms that are understandable to humans. Central to what is understandable is how explanations are communicated. Therefore, this survey provides a categorization of how recent interpretability methods communicate explanations and discusses the methods in depth. Furthermore, the survey focuses on post-hoc methods, which provide explanations after a model is learned and generally model-agnostic. A common concern for this class of methods is whether they accurately reflect the model. Hence, how these post-hoc methods are evaluated is discussed throughout the paper.","","","arXiv","2108.04840","cs.CL","madsen-etal-2021-posthoc","arXiv [cs.CL]"
"Conference Paper","Lee A,Auli M,Ranzato M","Discriminative Reranking for Neural Machine Translation","","","2021","","","7250-7264","PhD;PhD/To Read","NMT - Decoding strategies;NMT;OPS - Reranking","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.563;http://dx.doi.org/10.18653/v1/2021.acl-long.563;https://aclanthology.org/2021.acl-long.563.pdf","10.18653/v1/2021.acl-long.563","","Reranking models enable the integration of rich features to select a better output hypothesis within an n-best list or lattice. These models have a long history in NLP, and we revisit discriminative reranking for modern neural machine translation models by training a large transformer architecture. This takes as input both the source sentence as well as a list of hypotheses to output a ranked list. The reranker is trained to predict the observed distribution of a desired metric, e.g. BLEU, over the n-best list. Since such a discriminator contains hundreds of millions of parameters, we improve its generalization using pre-training and data augmentation techniques. Experiments on four WMT directions show that our discriminative reranking approach is effective and complementary to existing generative reranking approaches, yielding improvements of up to 4 BLEU over the beam search output.","","","","","","lee-etal-2021-discriminativeLee2021-jg",""
"Conference Paper","Voita E,Sennrich R,Titov I","Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation","","","2021","","","1126-1140","PhD;PhD/Read","NMT;INT - Intrinsic;Interpretability;OPS - LRP","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","Online","2021-08","","https://aclanthology.org/2021.acl-long.91;http://dx.doi.org/10.18653/v1/2021.acl-long.91","10.18653/v1/2021.acl-long.91","","In Neural Machine Translation (and, more generally, conditional language modeling), the generation of a target token is influenced by two types of context: the source and the prefix of the target sequence. While many attempts to understand the internal workings of NMT models have been made, none of them explicitly evaluates relative source and target contributions to a generation decision. We argue that this relative contribution can be evaluated by adopting a variant of Layerwise Relevance Propagation (LRP). Its underlying `conservation principle' makes relevance propagation unique: differently from other methods, it evaluates not an abstract quantity reflecting token importance, but the proportion of each token's influence. We extend LRP to the Transformer and conduct an analysis of NMT models which explicitly evaluates the source and target relative contributions to the generation process. We analyze changes in these contributions when conditioning on different types of prefixes, when varying the training objective or the amount of training data, and during the training process. We find that models trained with more data tend to rely on source information more and to have more sharp token contributions; the training process is non-monotonic with several stages of different nature.","","Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License","","","","voita-etal-2021-analyzing",""
"Preprint Manuscript","Kocmi T,Federmann C,Grundkiewicz R,Junczys-Dowmunt M,Matsushita H,Menezes A","To ship or not to ship: An extensive evaluation of automatic metrics for machine translation","","","2021","","","","PhD;PhD/Read","MET - Metric Evaluation;NMT;Meta;NMT - Metrics","","","","","","2021-07-22","","http://arxiv.org/abs/2107.10821","","2107.10821","Automatic metrics are commonly used as the exclusive tool for declaring the superiority of one machine translation system's quality over another. The community choice of automatic metric guides research directions and industrial developments by deciding which models are deemed better. Evaluating metrics correlations has been limited to a small collection of human judgements. In this paper, we corroborate how reliable metrics are in contrast to human judgements on - to the best of our knowledge - the largest collection of human judgements. We investigate which metrics have the highest accuracy to make system-level quality rankings for pairs of systems, taking human judgement as a gold standard, which is the closest scenario to the real metric usage. Furthermore, we evaluate the performance of various metrics across different language pairs and domains. Lastly, we show that the sole use of BLEU negatively affected the past development of improved models. We release the collection of human judgements of 4380 systems, and 2.3 M annotated sentences for further analysis and replication of our work.","","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","arXiv","2107.10821","cs.CL","kocmi-etal-2021-ship","arXiv [cs.CL]"
"Conference Paper","Yin K,Fernandes P,Pruthi D,Chaudhary A,Martins AF,Neubig G","Do Context-Aware Translation Models Pay the Right Attention?","","","2021","","","788-801","PhD;PhD/To Read","NMT;NMT - Context-aware;INT - Human Relevance;Interpretability","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.65;http://dx.doi.org/10.18653/v1/2021.acl-long.65;https://aclanthology.org/2021.acl-long.65/;http://arxiv.org/abs/2105.06977","10.18653/v1/2021.acl-long.65","","Context-aware machine translation models are designed to leverage contextual information, but often fail to do so. As a result, they inaccurately disambiguate pronouns and polysemous words that require context for resolution. In this paper, we ask several questions: What contexts do human translators use to resolve ambiguous words? Are models paying large amounts of attention to the same context? What if we explicitly train them to do so? To answer these questions, we introduce SCAT (Supporting Context for Ambiguous Translations), a new English-French dataset comprising supporting context words for 14K translations that professional translators found useful for pronoun disambiguation. Using SCAT, we perform an in-depth analysis of the context used to disambiguate, examining positional and lexical characteristics of the supporting words. Furthermore, we measure the degree of alignment between the model's attention scores and the supporting context from SCAT, and apply a guided attention strategy to encourage agreement between the two.","","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","","","","yin-etal-2021-context",""
"Conference Paper","Fernandes P,Yin K,Neubig G,Martins AF","Measuring and Increasing Context Usage in Context-Aware Machine Translation","","","2021","","","6467-6478","PhD;PhD/To Read","NMT - Context-aware;NMT;INT - Intrinsic;Interpretability;OPS - Conditional Cross-Mutual Information","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.505;http://dx.doi.org/10.18653/v1/2021.acl-long.505;https://aclanthology.org/2021.acl-long.505/;http://arxiv.org/abs/2105.03482","10.18653/v1/2021.acl-long.505","","Recent work in neural machine translation has demonstrated both the necessity and feasibility of using inter-sentential context, context from sentences other than those currently being translated. However, while many current methods present model architectures that theoretically can use this extra context, it is often not clear how much they do actually utilize it at translation time. In this paper, we introduce a new metric, conditional cross-mutual information, to quantify usage of context by these models. Using this metric, we measure how much document-level machine translation systems use particular varieties of context. We find that target context is referenced more than source context, and that including more context has a diminishing affect on results. We then introduce a new, simple training method, context-aware word dropout, to increase the usage of context by context-aware models. Experiments show that our method not only increases context usage, but also improves the translation quality according to metrics such as BLEU and COMET, as well as performance on anaphoric pronoun resolution and lexical cohesion contrastive datasets.","","","","","","fernandes-etal-2021-measuring",""
"Conference Paper","Wu T,Ribeiro MT,Heer J,Weld D","Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models","","","2021","","","6707-6723","PhD;PhD/Read","INT - Causal attribution;INT - Counterfactuals;Interpretability","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.523;http://dx.doi.org/10.18653/v1/2021.acl-long.523;https://aclanthology.org/2021.acl-long.523/","10.18653/v1/2021.acl-long.523","","While counterfactual examples are useful for analysis and training of NLP models, current generation methods either rely on manual labor to create very few counterfactuals, or only instantiate limited types of perturbations such as paraphrases or word substitutions. We present Polyjuice, a general-purpose counterfactual generator that allows for control over perturbation types and locations, trained by finetuning GPT-2 on multiple datasets of paired sentences. We show that Polyjuice produces diverse sets of realistic counterfactuals, which in turn are useful in various distinct applications: improving training and evaluation on three different tasks (with around 70% less annotation effort than manual generation), augmenting state-of-the-art explanation techniques, and supporting systematic counterfactual error analysis by revealing behaviors easily missed by human experts.","","","","","","wu-etal-2021-polyjuice",""
"Conference Paper","Cai D,Wang Y,Li H,Lam W,Liu L","Neural Machine Translation with Monolingual Translation Memory","","","2021","","","7307-7318","PhD;PhD/Read","NMT;NMT - Translation memory","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.567;http://dx.doi.org/10.18653/v1/2021.acl-long.567;https://aclanthology.org/2021.acl-long.567/","10.18653/v1/2021.acl-long.567","","Prior work has proved that Translation Memory (TM) can boost the performance of Neural Machine Translation (NMT). In contrast to existing work that uses bilingual corpus as TM and employs source-side similarity search for memory retrieval, we propose a new framework that uses monolingual memory and performs learnable memory retrieval in a cross-lingual manner. Our framework has unique advantages. First, the cross-lingual memory retriever allows abundant monolingual data to be TM. Second, the memory retriever and NMT model can be jointly optimized for the ultimate translation goal. Experiments show that the proposed method obtains substantial improvements. Remarkably, it even outperforms strong TM-augmented NMT baselines using bilingual TM. Owning to the ability to leverage monolingual data, our model also demonstrates effectiveness in low-resource and domain adaptation scenarios.","","http://creativecommons.org/licenses/by/4.0/","","","","cai-etal-2021-neural",""
"Conference Paper","Marie B,Fujita A,Rubino R","Scientific Credibility of Machine Translation Research: A Meta-Evaluation of 769 Papers","","","2021","","","7297-7306","PhD;PhD/Read","NMT;Meta;MET - Metric Evaluation;NMT - Metrics","Association for Computational Linguistics","Online","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","2021-08","","https://aclanthology.org/2021.acl-long.566;http://dx.doi.org/10.18653/v1/2021.acl-long.566;https://aclanthology.org/2021.acl-long.566/;https://arxiv.org/pdf/2106.15195","10.18653/v1/2021.acl-long.566","","This paper presents the first large-scale meta-evaluation of machine translation (MT). We annotated MT evaluations conducted in 769 research papers published from 2010 to 2020. Our study shows that practices for automatic MT evaluation have dramatically changed during the past decade and follow concerning trends. An increasing number of MT evaluations exclusively rely on differences between BLEU scores to draw conclusions, without performing any kind of statistical significance testing nor human evaluation, while at least 108 metrics claiming to be better than BLEU have been proposed. MT evaluations in recent papers tend to copy and compare automatic metric scores from previous work to claim the superiority of a method or an algorithm without confirming neither exactly the same training, validating, and testing data have been used nor the metric scores are comparable. Furthermore, tools for reporting standardized metric scores are still far from being widely adopted by the MT community. After showing how the accumulation of these pitfalls leads to dubious evaluation, we propose a guideline to encourage better automatic MT evaluation along with a simple meta-evaluation scoring method to assess its credibility.","","","","","","marie-etal-2021-scientific",""
"Conference Paper","Belinkov Y,Durrani N,Dalvi F,Sajjad H,Glass J","What do Neural Machine Translation Models Learn about Morphology?","","","2017","","","861-872","PhD;PhD/Read","NMT;Linguistic Properties;INT - Extrinsic","Association for Computational Linguistics","Vancouver, Canada","Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","2017-07","","https://www.aclweb.org/anthology/P17-1080;http://dx.doi.org/10.18653/v1/P17-1080;https://www.aclweb.org/anthology/P17-1080/","10.18653/v1/P17-1080","","Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.","Character-based representations are better than word-based ones for learning morphology, especially in rare and unseen words.Lower layers of the neural network are better at capturing morphology, while deeper net-works improve translation performance. We hypothesize that lower layers are more focused on word structure, while higher ones are focused on word meaning. Translating into morphologically-poorer languages leads to better source-side representations. This is partly, but not completely, cor-related with BLEU scores.The attentional decoder learns impoverished representations that do not carry much information about morphology.","","","","","belinkov-etal-2017-neural",""
"Conference Paper","Alvarez-Melis D,Jaakkola T","A causal framework for explaining the predictions of black-box sequence-to-sequence models","","","2017","","","412-421","PhD;PhD/Read","INT - Causal attribution;INT - Extrinsic;Interpretability","Association for Computational Linguistics","Stroudsburg, PA, USA","Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing","Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing","Copenhagen, Denmark","2017","","http://aclweb.org/anthology/D17-1042;http://dx.doi.org/10.18653/v1/d17-1042;https://www.aclweb.org/anthology/D17-1042;http://dx.doi.org/10.18653/v1/D17-1042;https://www.aclweb.org/anthology/D17-1042/;https://www.aclweb.org/anthology/D17-1042.pdf","10.18653/v1/d17-1042","","We interpret the predictions of any black-box structured input-structured output model around a specific input-output pair. Our method returns an ``explanation'' consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-to-sequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.","<br>","","","","","alvarez-melis-jaakkola-2017-causal",""
"Journal Article","Belinkov Y,Durrani N,Dalvi F,Sajjad H,Glass J","On the Linguistic Representational Power of Neural Machine Translation Models","Comput. Linguist.","Computational Linguistics","2020","46","1","1-52","PhD;PhD/To Read","NMT;Linguistic Properties;LIN - Semantics;LIN - Morphology;LIN - Syntax;NMT - Tokenization;NMT - Multilingual;Interpretability;INT - Probing Tasks;INT - Intrinsic","","","","","","2020-03","0891-2017","https://www.aclweb.org/anthology/2020.cl-1.1;http://dx.doi.org/10.1162/coli_a_00367;https://www.aclweb.org/anthology/2020.cl-1.1/;https://direct.mit.edu/coli/article-pdf/46/1/1/1847791/coli_a_00367.pdf","10.1162/coli_a_00367","","Despite the recent success of deep neural networks in natural language processing and other spheres of artificial intelligence, their interpretability remains a challenge. We analyze the representations learned by neural machine translation (NMT) models at various levels of granularity and evaluate their quality through relevant extrinsic properties. In particular, we seek answers to the following questions: (i) How accurately is word structure captured within the learned representations, which is an important aspect in translating morphologically rich languages? (ii) Do the representations capture long-range dependencies, and effectively handle syntactically divergent languages? (iii) Do the representations capture lexical semantics? We conduct a thorough investigation along several parameters: (i) Which layers in the architecture capture each of these linguistic phenomena; (ii) How does the choice of translation unit (word, character, or subword unit) impact the linguistic properties captured by the underlying representations? (iii) Do the encoder and decoder learn differently and independently? (iv) Do the representations learned by multilingual NMT models capture the same amount of linguistic information as their bilingual counterparts? Our data-driven, quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena. We show that deep NMT models trained in an end-to-end fashion, without being provided any direct supervision during the training process, learn a non-trivial amount of linguistic information. Notable findings include the following observations: (i) Word morphology and part-of-speech information are captured at the lower layers of the model; (ii) In contrast, lexical semantics or non-local syntactic and semantic dependencies are better represented at the higher layers of the model; (iii) Representations learned using characters are more informed about word-morphology compared to those learned using subword units; and (iv) Representations learned by multilingual models are richer compared to bilingual models.","Extended version of 'What do Neural Machine Translation Models Learn about Morphology?' in which the comparison between monolingual and multilingual model is added.","","","","","belinkov-etal-2020-linguistic",""
